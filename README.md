## Mismatched Crowdsourcing Automatic Speech Recognition
### Train an ASR directly from mismatched transcripts, based on kaldi/egs/librispeech.

<!-- https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet -->

Mismatched transcripts are produced by people writing down what they
hear in a language L2, as if it were nonsense syllables in their own
language, English.

This has two sources of variability, which we solve separately.

**English orthography** is solved by aligning a transcript to its audio with a nonsense-English ASR.

**L2-to-English misperception** is solved by generating candidate L2-word transcriptions,
using those to train an L2 recognizer, and then aligning them to the audio.
 
Implementing this requires these software components:
 
### 1. ENGLISH NONSENSE DICTIONARY

A pronunciation lexicon of English nonsense words, called `lexiconp.txt` by Kaldi.
Fortunately, its vocabulary is exactly the set of space-bounded words in Turker transcripts.
The software takes each word and looks in <http://www.isle.illinois.edu/sst/data/g2ps/English/English_ref_orthography_dict.html>
to find all of its pronunciations, and list them separately in `lexiconp.txt`.
The units of `English_ref_orthography_dict.txt` are designed so that you should prefer any digraph or trigraph to the single-grapheme.
To implement that, assign a probability to each pronunciation proportional to exp(-(number of entries from `English_ref_orthography.html` that were concatenated to form this candidate pronunciation)).

Scripts for this are in the subfolder `1-nonsenseDict`.
The script `1-nonsenseDict/split-words.rb` will also preprocess turker transcripts (like <https://github.com/uiuc-sst/PTgen/blob/master/steps/preprocess_turker_transcripts.pl>).

### 2. ENGLISH ASR AND FORCED ALIGNMENT

An English-language GMM-HMM ASR, trained using the `lexiconp.txt` from (1).
Treat every Turker transcription as an independent training token.
So if we have 3 transcriptions per utterance, then the amount of training data is 3 times the amount of audio.
Forced alignment then chooses the most likely pronunciation of each Turker nonsense word, maximizing p(audio|pronunciation). 

### 3. L2 PRONUNCIATION DICTIONARY IN TERMS OF ENGLISH PHONES

Take all available monolingual texts in L2.  LORELEI gives us 120k words of text in each foreign language, quite a lot.
Using this list of words,
the <http://www.isle.illinois.edu/sst/data/g2ps/> L2 reference orthography, and some kind of mapping from L2 phonemes to English phonemes,
generate another `lexiconp.txt`,
where each line contains an L2 word, a list of English phonemes, and this pronunciation's probability.

### 4. MINIMUM-STRING-EDIT GENERATION OF CANDIDATE L2 WORD TRANSCRIPTIONS

Calculate the 10 L2-word sequences that best match the English-phone transcripts
generated by forced alignment from each transcript (thus, 30 word sequences per utterance).

### 5. L2 PRONUNCIATION DICTIONARY IN TERMS OF L2 PHONES

Back off from (3) to a dictionary using L2 phones instead of English phones.

### 6. TRAIN AN L2 ASR.

Use the ASR to do forced alignment of the L2 word transcriptions from (5).
